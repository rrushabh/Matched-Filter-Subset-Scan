{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "regardless of matched filter or not, lots of different ways to do a log likelihood statistic\n",
    "\n",
    "two different sets of assumptions\n",
    "1. what we expect the data to look like if nothing is going on -> everything is drawn to some mean from historical data, and how is the data distributed (poisson, gaussian, binary)\n",
    "2. how things change for affected subset, q: coefficient. how different is the alternative hypothesis from the null.\n",
    "\n",
    "matched filter part:\n",
    "find a subset S and finter theta. theta is constrained to lie in some filter set. penalty based on how different s is from theta.\n",
    "If something in s and not in theta or vice versa then penalised. Amount of penalty is delta.\n",
    "\n",
    "search filter set and find 1-nearest neighbour according to L1 metric.\n",
    "\n",
    "using tree for filter set search:\n",
    "1. how do you learn the tree to begin with - multi-criterion decision tree. leaves of tree contain one or more filters. split on element contained or not.\n",
    "2. how do you implement search - \n",
    "in each internal node we need to know how many filters in each branch, and for each data element how many filters its included in.\n",
    "    you can either follow the branch conforming to your subset, or follow the other branch if you believe it will bring you to a closer filter.\n",
    "    if that other branch has a lot of filters in it, or if the filters are on average closer to your subset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HOW WE'RE COMPUTING Q INTERVALS\n",
    "\n",
    "for normal penalised scan, we have p value for each data point.\n",
    "for this p value we can get a qmin and qmax for each data point. interval for which data point makes positive contribution to the score.\n",
    "\n",
    "call this twice: one with 0 penalty, and one with score - delta (penalty of delta)\n",
    "    this gives us 4 points, q_{min,unpenalized}, q_{min,penalized}, q_{max,penalized}, q_{max,unpenalized}_i for each s_i\n",
    "\n",
    "take all of the distinct values given and sort them. this gives you 4N-1 intervals, each interval gives you a different combination of points.\n",
    "\n",
    "we also have positive or negative direction (q > 1 or q < 1), so we also restrict the set of q values in one of these directions.\n",
    "\n",
    "WEIGHTS\n",
    "\n",
    "Conditioned on a given q:\n",
    "LLR_i > Delta -> weight = Delta, element in initial subset\n",
    "0 < LLR_i < Delta -> weight = LLR_i, element in initial subset\n",
    "-Delta < LLR_i < 0 -> weight = LLR_i, element not in initial subset\n",
    "LLR_i < -Delta -> weight = Delta, element not in initial subset\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "WHAT TO DO ONCE WE FIND AN OPTIMAL FILTER\n",
    "\n",
    "if we were able to find a filter which minimises L1 distance to a subset, at a given q value, we know what the best subset is for that filter.\n",
    "subset can change because of q value:\n",
    "- data points are always included, always excluded or only included if included in the filter. so once we get the filter we might change our subset a bit.\n",
    "- once we have this new subset we compute qmle, add up all the counts, add up all the baselines, take the ratio. qmle is a different value from that q interval that we started out with.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = []\n",
    "\n",
    "q_values = []\n",
    "for i in range(len(S)):\n",
    "    q_values.append()\n",
    "\n",
    "'''\n",
    "Compute (q_{min,unpenalized}, q_{min,penalized}, q_{max,penalized}, q_{max,unpenalized})_i for each s_i\n",
    "Collect all distinct q_{min} and q_{max} values, sort them, and form ranges (no more than 4N)\n",
    "'''\n",
    "\n",
    "q_ranges = [(0, 1)]\n",
    "\n",
    "# for q_range in q_ranges:\n",
    "#     (q_min, q_max) = q_range\n",
    "#     q_temp = (q_min+q_max)/2\n",
    "#     converged = False\n",
    "#     while not converged:\n",
    "#         # computing LLR for each s_i? I thought LLR is calculated for the whole subset.\n",
    "#         # x_i*log(q) + μ_i*(1 - q)\n",
    "#         # # (log Pr(xi | qμi) − log Pr(xi | μi)) is it this?\n",
    "#         # # log(p(xi | Dist1)/p(xi | Dist0)) or this? what is Dist?\n",
    "#         LLRs = [compute_LLR(s, q_temp) for s in S]\n",
    "#         S_initial = [int(LLR_i > 0) for LLR_i in LLRs]\n",
    "#         F_max = sum([max(0, LLR_i) for LLR_i in LLRs])\n",
    "#         # Define weighted L1 distance metric D and find filter in filter set which minimises D, use tree?\n",
    "#         F = F_max = D(S_initial, theta)\n",
    "\n",
    "def compute_LLR(c_i, b_i, q):\n",
    "    return c_i*np.log(q) + b_i*(1 - q)\n",
    "\n",
    "for q_range in q_ranges:\n",
    "    (q_min, q_max) = q_range\n",
    "    q_temp = (q_min+q_max)/2\n",
    "    converged = False\n",
    "    while not converged:\n",
    "        # computing LLR for each s_i? I thought LLR is calculated for the whole subset.\n",
    "        # B = baselines\n",
    "        LLRs = [compute_LLR(s, b, q_temp) for s, b in zip(S, B)]\n",
    "        weights = []\n",
    "        S_initial = []\n",
    "        F_max = 0\n",
    "        for LLR_i in LLRs:\n",
    "            S_initial.append(int(LLR_i > 0))\n",
    "            weights.append(LLR_i) if abs(LLR_i) < Delta else weights.append(Delta)\n",
    "            F_max += max(0, LLR_i)\n",
    "        # Define weighted L1 distance metric D and find filter in filter set which minimises D, use tree?\n",
    "        '''\n",
    "        This is where the tree search goes\n",
    "        '''\n",
    "        F = F_max = D(S_initial, theta)\n",
    "\n",
    "'''\n",
    "For each q range (q_{min,range}, q_{max,range}):\n",
    "    q_{temp} = (q_{min,range} + q_{max,range}) / 2\n",
    "    converged = False\n",
    "    While not converged do:\n",
    "        Compute LLR_i for each s_i at the given q_{temp}\n",
    "        Define initial subset S: S_i = 1\\{ LLR_i > 0 \\}\n",
    "        Define maximum possible score: F_{max} = \\sum_i \\max(0, LLR_i)\n",
    "        Define weighted L1 distance metric: D(S, \\theta) = \\sum_i \\min(|LLR_i|,\\Delta) 1\\{S_i \\ne \\theta_i \\}\n",
    "        Find \\theta \\in \\Theta that (approximately) minimizes D(S, \\theta)\n",
    "        Compute score: F = F_{max} - D(S, \\theta)\n",
    "        Compute new S: S_i = 1\\{ LLR_i > \\Delta(1-2\\theta_i) \\}\n",
    "        Compute new q_{mle} of S\n",
    "        If (q_{mle} == q_{temp}):\n",
    "            converged = True\n",
    "        else:\n",
    "            q_{temp} = q_{mle}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    '''\n",
    "    Multi-criterion decision tree to search the filter set.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, split_element):\n",
    "        self.split_element = split_element\n",
    "        self.num_filters = 0\n",
    "        self.element_counts = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    # information gain for split element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s1  s2  s3  s4\n",
       "0   1   1   0   0\n",
       "1   0   1   1   0\n",
       "2   0   0   1   1\n",
       "3   1   1   1   0\n",
       "4   0   1   1   1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'s1':[1,0,0,1,0], 's2':[1,1,0,1,1], 's3':[0,1,1,1,1], 's4':[0,0,1,0,1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s2  s3  s4\n",
       "0   1   0   0\n",
       "3   1   1   0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['s1'] == 1].drop(['s1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    size = data.shape[0]\n",
    "    props = [((data[col] == 0).sum(), (data[col] == 1).sum()) for col in data.columns]\n",
    "    ent = -sum([num_0/size*np.log2(num_0/size) + (num_1/size*np.log2(num_1/size)) for (num_0, num_1) in props if num_0*num_1 > 0]) # if either prop_0 or prop_1 = 0 then entropy = 0\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.385757378684062\n"
     ]
    }
   ],
   "source": [
    "print(entropy(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gains(data):\n",
    "    size = data.shape[0]\n",
    "    entropy_before = entropy(data)\n",
    "    info_gains = []\n",
    "    for col in data.columns:\n",
    "        left, right = data[data[col] == 0], data[data[col] == 1]\n",
    "        left_size, right_size = left.shape[0], right.shape[0]\n",
    "        entropy_after = (left_size/size)*entropy(left) + (right_size/size)*entropy(right)\n",
    "        info_gains.append(entropy_before - entropy_after)\n",
    "    return info_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s1'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8838023778186743, 1.2877123795494492, 1.2877123795494492, 1.8838023778186743]\n"
     ]
    }
   ],
   "source": [
    "def build_tree_rec(data):\n",
    "    num_filters = data.shape[0]\n",
    "    element_counts = [(data[col] == 1).sum() for col in data.columns]\n",
    "    max_ig_element = data.columns[np.argmax(info_gains(data))[0]]\n",
    "    tree = Node(max_ig_element, num_filters, element_counts)\n",
    "    tree.left = build_tree_rec(data[data[max_ig_element] == 0])\n",
    "    tree.right = build_tree_rec(data[data[max_ig_element] == 1])\n",
    "    '''\n",
    "    PROBLEM: the ID3 algorithm removes the element we just made a split on for the next split.\n",
    "             but we want to keep element counts at all nodes. so we need to include this element.\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Extra check: if nothing is splitting the data then stop expanding\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Bound depth of decision tree: root n\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stack for storing the other branches\n",
    "For now: if rules give different branches then pick one and push the other to the stack.\n",
    "Later: only push other to stack if it is better by some margin.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Traversing the tree: elements have weights\n",
    "If rules give different branches then pick one: we should be more likely to pick the branch\n",
    "that contains the element, if the element has a high weight.\n",
    "- At each node: calculate distance to estimate filter (from summary statistics) in each branch\n",
    "'''\n",
    "\n",
    "'''\n",
    "Traversing the tree:\n",
    "assuming IID, we can calculate a mean and s.d. weighted distance to any filter for each of the two branches.\n",
    "take 20 draws from this gaussian distribution, take the lowest of these draws.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tree traversal: take in subset and weights for each element\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "OTHER IDEA\n",
    "\n",
    "Binary decision diagrams\n",
    "Ways of representing sets of subsets\n",
    "Variant: Zero-suppressed binary decision diagrams - only the things that correspond to actual subsets.\n",
    "https://en.wikipedia.org/wiki/Zero-suppressed_decision_diagram\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
