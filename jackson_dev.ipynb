{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters = np.random.randint(2, size= (1000, 100))\n",
    "# filters = pd.read_csv(r\"C:\\Users\\joles\\Downloads\\ex_filter_set (1).csv\").drop('Unnamed: 0', axis = 1)\n",
    "# filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    '''\n",
    "    Multi-criterion decision tree to search the filter set.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    def __init__(self, theta:pd.DataFrame, depth = None, max_depth = None, num_filters = None):\n",
    "        \n",
    "        self.num_filters = num_filters if num_filters else 0\n",
    "        # self.min_filters = min_filters if min_filters else 0\n",
    "\n",
    "        self.depth = depth if depth else 0\n",
    "        \n",
    "        #Max depth = size of subset\n",
    "        self.max_depth = max_depth if max_depth else 1\n",
    "\n",
    "        #initialize left and right node to be empty\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "        #filter set\n",
    "        self.theta = theta\n",
    "        \n",
    "    def calc_weights(self, filters, depth):\n",
    "        d = depth\n",
    "        w1 = sum(filters[d])/(filters[d].shape[0])\n",
    "        w2 = 1 - w1\n",
    "        return w1, w2\n",
    "    \n",
    "    #returns the 'average' filter\n",
    "    def GET_avg(self):\n",
    "        sums = np.array([self.theta[col].sum() for col in self.theta.columns])\n",
    "        return sums/(self.theta.shape[0])\n",
    "\n",
    "    #calculate entropy on split element\n",
    "    @staticmethod\n",
    "    def calc_entropy(df):\n",
    "        \n",
    "        size = df.shape[0]\n",
    "        props = [((df[col] == 0).sum(), (df[col] == 1).sum()) for col in df.columns]\n",
    "\n",
    "        s = 0\n",
    "        for prop in props:\n",
    "            if prop[0]*prop[1] > 0:\n",
    "                s = s + (prop[0]/size*np.log(prop[0]/size)) + (prop[1]/size*np.log(prop[1]/size))\n",
    "        return -s \n",
    "    \n",
    "\n",
    "    # information gain for split element\n",
    "    \n",
    "    def info_gains(self, data):\n",
    "        size = data.shape[0]\n",
    "        entropy_before = self.calc_entropy(data)\n",
    "        info_gains = []\n",
    "        for col in data.columns:\n",
    "            left, right = data[data[col] == 0], data[data[col] == 1]\n",
    "            left_size, right_size = left.shape[0], right.shape[0]\n",
    "            entropy_after = (left_size/size)*self.calc_entropy(left) + (right_size/size)*self.calc_entropy(right)\n",
    "            info_gains.append(entropy_before - entropy_after)\n",
    "        return info_gains\n",
    "\n",
    "    \n",
    "    def build_tree(self):\n",
    "\n",
    "        filters = self.theta\n",
    "\n",
    "        self.split_elem = filters.columns[np.argmax(self.info_gains(filters))]\n",
    "        \n",
    "        l_split = filters[filters[self.split_elem] == 0]\n",
    "        r_split = filters[filters[self.split_elem] == 1]   \n",
    "\n",
    "        if (self.depth < self.max_depth) and (self.num_filters > 1):\n",
    "\n",
    "            \n",
    "            left = Node(l_split,\n",
    "                        self.depth + 1,\n",
    "                        self.max_depth,\n",
    "                        num_filters = l_split.shape[0])\n",
    "            \n",
    "            self.left = left\n",
    "            left.build_tree()\n",
    "\n",
    "            right = Node(r_split,\n",
    "                        self.depth + 1,\n",
    "                        self.max_depth,\n",
    "                        num_filters = r_split.shape[0])\n",
    "             \n",
    "            self.right = right\n",
    "            right.build_tree()\n",
    "\n",
    "    \n",
    "    #Next three methods involve choosing correct branch based on Gaussian approach on 'n' iid filters. \n",
    "    #Filters may not be iid. Need to find a general method for choosing correct branch?\n",
    "    def calc_mean_distance(self, subset, weights):\n",
    "        return sum([weights[i] * (self.GET_avg()[i]+(1-2*self.GET_avg()[i])*subset[i]) for i in range(len(subset))])\n",
    "\n",
    "    def calc_variance(self, weights):\n",
    "        return sum([(weights[i]**2) * self.GET_avg()[i]*(1-self.GET_avg()[i]) for i in range(len(self.GET_avg()))])\n",
    "\n",
    "    def choose_branch(self, subset, weights):\n",
    "\n",
    "        #distance to average filter\n",
    "        left_avg = self.left.calc_mean_distance(subset=subset, weights=weights)\n",
    "        right_avg = self.right.calc_mean_distance(subset=subset, weights=weights)\n",
    "\n",
    "        #calculate variance of distance\n",
    "        left_var = self.left.calc_variance(weights=weights)\n",
    "        right_var = self.right.calc_variance(weights=weights)\n",
    "\n",
    "        #calculate minimum expected distance to average filter\n",
    "        ex_distance_left = left_avg - pow(left_var, 0.5)*math.sqrt(2*np.log(self.left.theta.shape[0]))\n",
    "        ex_distance_right = right_avg - pow(right_var, 0.5)*math.sqrt(2*np.log(self.right.theta.shape[0]))\n",
    "\n",
    "        if ex_distance_left <= ex_distance_right:\n",
    "            return self.left\n",
    "        else:\n",
    "            return self.right\n",
    "\n",
    "        # return min(ex_distance_left , ex_distance_right)\n",
    "        \n",
    "    def traverse(self, subset, weights):\n",
    "        while self.depth < self.max_depth:\n",
    "            self = self.choose_branch(subset, weights)\n",
    "\n",
    "        temp_min = 1000000000\n",
    "        temp_filter = np.zeros(self.theta.shape[1])\n",
    "\n",
    "        for i in range(self.theta.shape[0]):\n",
    "            dist = sum(weights*abs(self.theta.iloc[i] - subset))\n",
    "            if dist < temp_min:\n",
    "                temp_min = dist\n",
    "                temp_filter = self.theta.iloc[i]\n",
    "\n",
    "        print(\"Best Matched Filter: \\n{}\\n  with weighted L1 distance of: {}\".format(temp_filter, temp_min) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = pd.DataFrame([[0, 1, 1, 0],\n",
    "                     [0, 0, 1, 1],\n",
    "                     [1, 1, 0, 0],\n",
    "                     [1, 1, 1, 0],\n",
    "                     [0, 1, 1, 1]])\n",
    "subset = np.array([0,1,0,0])\n",
    "weights = np.array([0.5,1,1,1])\n",
    "\n",
    "\n",
    "theta2 = pd.DataFrame([[1, 1, 0, 0, 0],\n",
    "                        [1, 1, 1, 0, 0],\n",
    "                        [0, 1, 1, 0, 0],\n",
    "                        [0, 1, 1, 1, 0],\n",
    "                        [0, 0, 0, 1, 1],\n",
    "                        [0, 0, 1, 1, 0],\n",
    "                        [0, 0, 1, 1, 1]])\n",
    "\n",
    "subset2 = np.array([0, 1, 1, 1, 1])\n",
    "weights2 = np.array([1, 0.5, 1, 1, 0.3])\n",
    "\n",
    "root = Node(theta = theta2, max_depth = 1, num_filters=theta.shape[0])\n",
    "root.build_tree()\n",
    "root.traverse(subset2, weights2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29d3f7eede10c00fe45892452721a4933fb3b4df7d5bb862d2c41a003536453b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
