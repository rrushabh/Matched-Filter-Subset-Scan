{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Node:\n",
    "    '''\n",
    "    Multi-criterion decision tree to search the filter set.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    def __init__(self, theta:pd.DataFrame, name, depth = None):\n",
    "        \n",
    "        self.name = name\n",
    "        self.num_filters = theta.shape[0]\n",
    "        self.depth = depth if depth else 0\n",
    "\n",
    "        # initialize left and right node to be empty\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "        # filter set is only stored for leaves\n",
    "        self.theta = None\n",
    "        \n",
    "        # average filter\n",
    "        self.avg_filter = theta.mean(axis=0) #.to_numpy()\n",
    "\n",
    "    #calculate entropy on split element\n",
    "    @staticmethod\n",
    "    def calc_entropy(df):       \n",
    "        return -df.mean(axis=0).apply(lambda x: x*np.log(x)+(1-x)*np.log(1-x) if x*(1-x)>0 else 0).sum()   \n",
    "\n",
    "    # information gain for split element   \n",
    "    def info_gains(self, data):\n",
    "        size = data.shape[0]\n",
    "        entropy = self.calc_entropy(data)\n",
    "        info_gains = []\n",
    "        for i in range(len(data.shape[1])):\n",
    "            left, right = data[data[:,i] == 0], data[data[:,i] == 1]\n",
    "            left_size, right_size = left.shape[0], right.shape[0]\n",
    "            \n",
    "            ig = (left_size/size)*self.calc_entropy(left) + (right_size/size)*self.calc_entropy(right)\n",
    "            info_gains.append(entropy - ig)\n",
    "\n",
    "        return info_gains\n",
    "    \n",
    "    def build_tree(self, theta, max_depth=100, min_filters_to_split=2):\n",
    "\n",
    "        if (self.depth < max_depth) and (self.num_filters >= min_filters_to_split):\n",
    "        \n",
    "            filters = theta\n",
    "            all_info_gains = self.info_gains(filters)\n",
    "            self.split_elem = filters.columns[np.argmax(all_info_gains)]\n",
    "        \n",
    "            #print(\"For node\",self.name,\", with\",self.num_filters,\"filters averaging\",self.avg_filter,\", we split on element\",self.split_elem,\"with information gain\",all_info_gains[self.split_elem])\n",
    "        \n",
    "            l_split = filters[filters[self.split_elem] == 0]\n",
    "            r_split = filters[filters[self.split_elem] == 1]   \n",
    "            \n",
    "            left = Node(l_split, self.name + \"L\",\n",
    "                        self.depth + 1)\n",
    "            \n",
    "            self.left = left\n",
    "            left.build_tree(l_split, max_depth, min_filters_to_split)\n",
    "\n",
    "            right = Node(r_split, self.name + \"R\",\n",
    "                        self.depth + 1)\n",
    "             \n",
    "            self.right = right\n",
    "            right.build_tree(r_split, max_depth, min_filters_to_split)\n",
    "            \n",
    "        else:\n",
    "            #print(\"Node\",self.name,\", with\",self.num_filters,\"filters averaging\",self.avg_filter,\", is a leaf node\")\n",
    "            self.theta = theta  # store filter set in leaf nodes only\n",
    "\n",
    "    \n",
    "    #Next three methods involve choosing correct branch based on Gaussian approach on 'n' iid filters. \n",
    "    #Filters may not be iid. Need to find a general method for choosing correct branch?\n",
    "    def calc_mean_distance(self, subset, weights):\n",
    "        return sum([weights[i] * (self.avg_filter[i]+(1-2*self.avg_filter[i])*subset[i]) for i in range(len(self.avg_filter))])\n",
    "\n",
    "    def calc_variance(self, weights):\n",
    "        return sum([(weights[i]**2) * self.avg_filter[i]*(1-self.avg_filter[i]) for i in range(len(self.avg_filter))])\n",
    "\n",
    "    def choose_branch(self, subset, weights):\n",
    "\n",
    "        #distance to average filter\n",
    "        left_avg = self.left.calc_mean_distance(subset=subset, weights=weights)\n",
    "        right_avg = self.right.calc_mean_distance(subset=subset, weights=weights)\n",
    "\n",
    "        #calculate variance of distance\n",
    "        left_var = self.left.calc_variance(weights=weights)\n",
    "        right_var = self.right.calc_variance(weights=weights)\n",
    "\n",
    "        #calculate minimum expected distance to average filter\n",
    "        ex_distance_left = left_avg - math.sqrt(2*left_var*np.log(self.left.num_filters))\n",
    "        ex_distance_right = right_avg - math.sqrt(2*right_var*np.log(self.right.num_filters))\n",
    "        print(\"Comparing\",self.left.name,\"(distance\",ex_distance_left,\") and\",self.right.name,\"(distance\",ex_distance_right,\")\")\n",
    "\n",
    "        if ex_distance_left <= ex_distance_right:\n",
    "            return self.left\n",
    "        else:\n",
    "            return self.right\n",
    "        \n",
    "    def traverse(self, subset, weights):\n",
    "        while (self.theta is None): # traverse the tree until we hit a leaf node\n",
    "            self = self.choose_branch(subset, weights)\n",
    "\n",
    "        print(\"Searching node\",self.name,\"with\",self.num_filters,\"filters\")\n",
    "        #print(self.theta)\n",
    "            \n",
    "        temp_min = 1000000000\n",
    "        temp_filter = np.zeros(self.theta.shape[1])\n",
    "\n",
    "        for i in range(self.theta.shape[0]):\n",
    "            dist = sum(weights*abs(self.theta.iloc[i] - subset))\n",
    "            if dist < temp_min:\n",
    "                temp_min = dist\n",
    "                temp_filter = self.theta.iloc[i]\n",
    "\n",
    "        print(\"Best Matched Filter: \\n{}\\n  with weighted L1 distance of: {}\".format(temp_filter, temp_min) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD INFO_GAINS METHOD\n",
    "\n",
    "# def info_gains(self, data):\n",
    "#         size = data.shape[0]\n",
    "#         entropy_before = self.calc_entropy(data)\n",
    "#         info_gains = []\n",
    "#         for col in data.columns:\n",
    "#             left, right = data[data[col] == 0], data[data[col] == 1]\n",
    "#             left_size, right_size = left.shape[0], right.shape[0]\n",
    "#             entropy_after = (left_size/size)*self.calc_entropy(left) + (right_size/size)*self.calc_entropy(right)\n",
    "#             info_gains.append(entropy_before - entropy_after)\n",
    "#         return info_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4840/943185490.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_filters_to_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# recursively creates the entire tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4840/2557422591.py\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(self, theta, max_depth, min_filters_to_split)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mall_info_gains\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo_gains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_elem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_info_gains\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4840/2557422591.py\u001b[0m in \u001b[0;36minfo_gains\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minfo_gains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0minfo_gains\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4840/2557422591.py\u001b[0m in \u001b[0;36mcalc_entropy\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcalc_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# information gain for split element\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "# sample case from Daniel - heuristic finds correct leaf\n",
    "#theta = pd.DataFrame([[0, 1, 1, 0],\n",
    "#                     [0, 0, 1, 1],\n",
    "#                     [1, 1, 0, 0],\n",
    "#                     [1, 1, 1, 0],\n",
    "#                     [0, 1, 1, 1]])\n",
    "theta = np.array([[0, 1, 1, 0],\n",
    "                  [0, 0, 1, 1],\n",
    "                  [1, 1, 0, 0],\n",
    "                  [1, 1, 1, 0],\n",
    "                  [0, 1, 1, 1]])\n",
    "\n",
    "subset = np.array([0,1,0,0])\n",
    "weights = np.array([0.5,1,1,1])\n",
    "\n",
    "# sample case from Jackson - heuristic does not find correct leaf\n",
    "#theta = pd.DataFrame([[1, 1, 0, 0, 0],\n",
    "#                        [1, 1, 1, 0, 0],\n",
    "#                        [0, 1, 1, 0, 0],\n",
    "#                        [0, 1, 1, 1, 0],\n",
    "#                        [0, 0, 0, 1, 1],\n",
    "#                        [0, 0, 1, 1, 0],\n",
    "#                        [0, 0, 1, 1, 1]])\n",
    "#subset = np.array([0, 1, 1, 1, 1])\n",
    "#weights = np.array([1, 0.5, 1, 1, 0.3])\n",
    "\n",
    "# random filters ###########\n",
    "# theta = pd.DataFrame(np.random.randint(2, size= (10000, 100)))\n",
    "# subset = np.random.randint(2, size=100)\n",
    "# weights = np.random.uniform(size=100)\n",
    "########################################\n",
    "\n",
    "# load filters from file\n",
    "# theta = pd.read_csv(r\"C:\\Users\\joles\\Downloads\\ex_filter_set (1).csv\").drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "# theta = pd.DataFrame([[0, 1, 1],\n",
    "#                       [0, 1, 0],\n",
    "#                       [1, 0, 1]])\n",
    "# subset = [1, 1, 1]\n",
    "# weights = [0.307, 0.39, 0.424]\n",
    "\n",
    "root = Node(theta = theta, name = \"*\")\n",
    "root.build_tree(theta,min_filters_to_split=2) # recursively creates the entire tree\n",
    "root.traverse(subset, weights)\n",
    "print()\n",
    "rightanswer = Node(theta = theta, name = \"***\")\n",
    "rightanswer.build_tree(theta,max_depth=0)\n",
    "rightanswer.traverse(subset,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes:\n",
    "#Tree may be biased towards first/leftmost elements,\n",
    "#it has some inertia before switching to best filter in traversal algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "29d3f7eede10c00fe45892452721a4933fb3b4df7d5bb862d2c41a003536453b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
